[TOC]

# 2.4-比较检验

使用某种**实验评估方法**测得学习器的某个**性能度量结果**，之后对结果进行比较，但比较并非直接比较性能度量的值，**性能比较**涉及几个重要因素：

1. 比较泛化性能，通过实验评估方法获得的是测试集上的性能，二者对比结果未必相同。
2. 测试集上的性能 与测试集的选择有关，且即使相同测试集，但测试样例不同，测试结果也不同。
3. 机器学习算法本身有一定随机性。

(默认**错误率**为性能度量，符合为$$\epsilon$$)

**统计假设检验**为性能比较提供依据，2种基本假设检验如下：

## 2.4.1-假设检验

- 对象

对**单个学习器**泛化性能比较，使用了二项检验、t检验方法。

- 介绍

**假设**是指对学习器**泛化错误率分布**的某种**判断或猜想。**

实际中不清楚学习器的泛化错误率，只能得到其**测试错误率$$\hat {\epsilon}$$**，二者未必相同，但接近可能性较大，故可**根据测试错误率估推泛化错误率的分布**。

泛化错误率$$\epsilon$$：学习器**在1个样本上犯错的概率**=$$\epsilon$$。

测试错误率$$\hat \epsilon $$：在**m个测试样本中恰有$$(\hat\epsilon* m)$$个被误分类**。

若测试样本从样本总体分布中独立采样获得，而泛化错误率$$\epsilon $$的学习器将其中m^'^个样本误分类、其余样本全都分类正确的概率是**$$\epsilon  ^{m^{'}}(1- \epsilon ^{m-m^{'}})$$**；则估算出其恰将$$\hat \epsilon  * m$$个样本全部误分类的概率如下所示，也表示包含m个样本的测试集上，泛化错误率为$$\epsilon $$的学习器被测得测试错误率$$\hat { \epsilon }$$的概率：
$$
P(\hat {\epsilon};\epsilon)=\binom{m}{\hat {\epsilon}*m}\epsilon ^{\hat {\epsilon}*m} (1-\epsilon)^{m-\hat{ \epsilon }*m } \qquad (2.4-1)
$$

- **二项检验**

给定测试错误率，则解偏导数得到，$$P(\hat {\epsilon};\epsilon)$$在$$ {\epsilon}=\hat \epsilon$$时最大，$$ {\epsilon}到\hat \epsilon$$距离增大时P减小，符合**二项分布**。

补充：

1. $$置信度是1-\alpha。 \\
   置信水平是指总体参数值落在样本统计值某一区内的概率，一般用1-\alpha表示；\\
   而置信区间是指在某一置信水平下，样本统计值与总体参数值间误差范围。$$
2. s.t.是”subject to“的简写，使左边式子在右边条件满足时成立。



使用二项检验，考虑假设”$$ {\epsilon} \le \epsilon_{0}$$“，则在$$1-\alpha$$的概率内所能观测到的最大错误率如下：
$$
\overline \epsilon = max\quad \epsilon \qquad s.t. \sum_{i=\epsilon _0 *m+1}^{m} \binom{m}{i} \epsilon ^i {(1-\epsilon)}^{m-i}< \alpha \qquad (2.4-2)
$$
此时若$$测试错误率\hat {\epsilon} < 临界值 \overline \epsilon$$，则根据二项检验可得出结论：在$$\alpha$$的显著度下，假设”$$ {\epsilon} \le \epsilon_{0}$$“不能被拒绝，即能以$$1-\alpha$$的置信度认为，学习器的泛化错误率不大于$$\epsilon_{0}$$；否则该假设可被拒绝。



一般是多次重复留出法或交叉验证法等进行多次训练/测试，这会得到多个测试错误率，使用“t检验”。

假定得到了k个测试错误率，$${\hat \epsilon}_1,{\hat \epsilon}_2,...,{\hat \epsilon}_k$$，从而引入平均测试错误率$$\mu$$和方差$$\sigma^2$$，如下：
$$
\mu = \frac{1}{k} \sum_{i=1}^{k} {\hat \epsilon }_i \qquad (2.4-3)\\
\sigma ^2 = \frac{1}{k-1} \sum_{i=1}^{k}({\hat \epsilon }_i-\mu)^2 \qquad (2.4-4)
$$
考虑到k个测试错误率可看作泛化错误率$$\epsilon_0$$的独立采样，则变量
$$
\tau_t=\frac{\sqrt{k}(\mu -\epsilon _0) }{\sigma} \qquad (2.4-5)
$$
服从自由度为k-1的t分布。

## 2.4.2-交叉验证t检验

- 对象

对**不同学习器性能**进行比较。

- 方法

对学习器A和B，使用k折交叉验证法分别2得到测试错误率$$\epsilon_1^A,...,\epsilon_k^A和\epsilon_1^B,...,\epsilon_k^AB$$，其中$$\epsilon_i^A和\epsilon_i^B$$是在相同第i折训练/测试集上得到的结果，可用k折交叉验证“成对t检验”。

思想：若2个学习器的**性能相同**，则使用**相同的训练集/测试集**得到的**测试错误率相同**，即**$$\epsilon_i^A=\epsilon_i^B$$**。

先对每队结果**求差**，即$$\Delta _i=\epsilon_i^A-\epsilon_i^B$$；若2个学习器性能相同，则**差值均值=0**.因此，据差值$$\Delta_1,...,\Delta_k$$来对“学习器A和B性能相同”这个假设做t检验，得到均值$$\mu$$和方差$$\sigma^2$$，在显著度$$\alpha$$下，若变量
$$
\tau_t=\left |\frac{\sqrt{k}\mu  }{\sigma}  \right | \qquad (2.4-6)
$$
小于临界值$$t_{\alpha /2,k-1}$$，则假设不能被拒绝，认为学习器A和B性能没有显著差异；否则**存在显著差异**，且**平均错误率较小**的那个学习器性能**较优**。

$$t_{\alpha /2,k-1}$$是自由度k-1的t分布上尾部累积分布为$$\alpha/2$$的临界值。

- 问题

假设检验有效的1个重要**前提**是测试错误率均为泛化错误率的**独立采样**。

然而实际由于**样本有限**，在使用交叉验证等实验估计方法时，不同轮次的训练集会有一定程度上的**重叠**，使得**测试错误率**实际上**并不独立**，会导致**过高估计假设成立**的概率，为缓解这一问题，可采用“**5*2交叉验证法**”，即做5次2折交叉验证，每次2折交叉验证之前随机将数据打乱，使得5次交叉验证中的数据划分不重复。

## 2.4.3-McNemar检验

- 对象

对于**二分类问题**、使用**留出法**，**不同学习器**的**性能比较**。

- 内容

就二分类问题，使用留出法时，可获得学习器A和B的测试错误率且得到分类结果的差别，即**都正确、都错误、1对1错**，“**列联表**”如下：

|           |   算法A    |            |
| :-------: | :--------: | :--------: |
| **算法B** |    正确    |    错误    |
|   正确    | $$e_{00}$$ | $$e_{01}$$ |
|   错误    | $$e_{10}$$ | $$e_{11}$$ |

若假设学习器A和B性能相同，则应有$$e_{01}=e_{10}$$，其变量$$|e_{01}-e_{10}|$$应服从正态分布，且均值为1，以及其他衍生而出的变量服从另外一些分布。当变量满足条件，则假设成立，即A和B性能没有显著差异，否则两者性能有显著差异，且平均错误率小的学习器性能更优。

## 2.4.4-Friedman检验与Nemenyi后续检验

- 对象

对于多个数据集，多个学习器进行性能比较。

- 内容

  当有多个学习器参与比较时，

  - 一种方法是在每个数据集上分布列出两两比较的结果，而在两两比较时可使用交叉验证t检验。
  - 另一种方法更为直接，使用基于算法排序的Friedman检验。

- 案例

用$$D_1、D_2、D_3、D_4$$4个数据集对算法$$A、B、C$$比较。

1. 使用留出法或交叉验证法得到每个算法在每个数据集上的测试结果。

2. 在每个数据集上根据测试性能由好到坏排序，并赋予序值1、2...；若算法的测试性能相同，则评分序值，如：

   |    数据集    | 算法A | 算法B | 算法C |
   | :----------: | :---: | :---: | :---: |
   |   $$D_1$$    |   1   |   2   |   3   |
   |   $$D_2$$    |   1   |  2.5  |  2.5  |
   |   $$D_3$$    |   1   |   2   |   3   |
   |   $$D_4$$    |   1   |   2   |   3   |
   | **平均序值** |   1   | 2.125 | 2.875 |

3. 使用Friedman检验来判断算法是否性能相同。若相同，则它们平均序值应当相同。如假定在N个数据集上比较k个算法，令$$r_i$$表示第i个算法的平均序值，先暂不讨论平分序值的情况，则$$r_i$$服从正态分布，其衍生变量也服从卡方分布。

4. 上述“原始Friedman检验”过于保守，现使用新的衍生变量，其服从F分布。

5. 若“所有算法性能相同”的假设被拒绝，则算法性能显著不同，此时用“后续验证”来进一步区分各算法，常用有“Nemenyi后续检验”。

6. Nemenyi后续检验计算出平均序值差别的临界值域$$CD$$。若2个算法的平均序值之差超过临界值域$$CD$$，则以相应的置信度拒绝“2个算法性能相同”这一假设。

7. 上述检验可以直观使用Friedman检验图显示。