[TOC]

# 2.3-性能度量

对学习器泛化性能的评估，不仅要实验估计方法，还有**衡量模型泛化能力的评价标准**，即性能度量。

性能度量反映任务需求，模型的“好坏”是相对的，不仅取决于算法和数据，还决定于任务需求。

不同任务的性能度量标准不相同，如下：

- 预测任务。

  - 给定样例集D={(x1, y1)...}，其中yi是示例xi的真实标记，评价学习器f的性能，即把**学习器预测结果f(x)**与**真实标记y**进行比较。

- 回归任务。

  - 最常用的性能度量是**均方误差**。

  $$
  E(f;D)\quad=\quad \frac{1}{m}\sum_{i=1}^{m}(f(x_i)-y_i)^2 \qquad (2.3-1)
  $$

  

  - 更一般的，对于数据分布D概率密度函数p(.)，均方误差描述为

  $$
  E(f;D)\quad=\quad \int_{x\sim D}^{} (f(x)-y)^2p(x)dx \qquad (2.3-2)
  $$

- 分类任务。

  - 常用性能度量如下。

## 2.3.1-错误率与精度

分类任务最常用的2种性能度量，适用于二分类任务，也适用于多分类任务。

- 错误率。

  - 分类错误样本占样本总数的比例。

  - $$
    E(f;D)\quad =\quad \frac{1}{m}\sum_{i=1}^{m} Ⅱ(f(x_i)\neq y_i)\quad (2.3-3)
    $$

    - Ⅱ(f(xi) ≠ yi)是指如果f(xi) = yi则等于0，否则为1。

- 精度。

  - 分类正确的样本数占样本总数的比例。

  - $$
    acc(f;D)\quad =\quad \frac{1}{m}\sum_{i=1}^{m} Ⅱ(f(x_i)= y_i)\quad = 1-E(f;D) \quad (2.3-4)
    $$

- 更一般的，对于数据分布D和概率密度函数p(.)定义：

  - 错误率。
    - ![](E:\affairs\my_affairs\extended_learning\notes\pics\image-20220819100429947.png)(2.3-5)
  - 精度。
    - ![](E:\affairs\my_affairs\extended_learning\notes\pics\image-20220819100516593.png)(2.3-6)

## 2.3.2-查准率、查全率与F1

### 意义

错误率和精度虽常用，但存在局限，如“挑出西瓜中有多少比例是好瓜”之类，由此引入查准率(precision)、查全率(recall)等性能度量。

### 分类结果混淆矩阵

对于二分类问题，将样例根据真实类别与学习器预测类别的**组合划分**，得到**混淆矩阵**。

（true、false、positive、negative）

|              | 预测结果   |            |
| ------------ | ---------- | ---------- |
| **真实情况** | 正例       | 反例       |
| 正例         | TP(真正例) | FN(假反例) |
| 反例         | FP(假正例) | TN(真反例) |

其中存在如下关系：
$$
1、TP+FP+FN+TN=\text{样例总数}\qquad (2.3-7)\\
2、查准率P=\frac{TP}{TP+FP}\qquad (2.3-8)\\
3、查全率R=\frac{TP}{TP+FN}\qquad (2.3-9)
$$

### 关系

查准率和查全率是1对矛盾的度量。

一般，查准率高时，查全率R会偏低，反之一样。

举例：

查全率高，查准率低：希望尽可能多地选出好瓜，则要增加选瓜的数量，极限情况是选出所有瓜，从而好瓜都选出来，因此查准率P的分母增大，导致P降低；而查全率R，其分母不变，分子TP变大，从而提高。

### P-R图（查准率-查全率曲线）

根据学习器预测结果对样例排序，排在前面的是学习器认为“最可能”正例的样本，按此规则逐个把样本作为正例进行预测，则每次可计算当前的P、R；以查准率P为纵轴、查全率R为横轴，如下图：

![](E:\affairs\my_affairs\extended_learning\notes\pics\image-20220822110206504.png)(图2.3-1)

特性：

1、学习器C的PR曲线被学习器A的曲线**完全“包住”**，则认为A的**性能优于**C。

2、若曲线发生交叉，很难说明优劣。因此设计新的性能度量，如下：

- **平衡点**(Break-Event Point，BEP)

是“查准率=查全率”时的取值，**BEP值大的其学习器性能更优**。

图2.3-1中，基于BEP，认为A的性能优于B。

- **F1度量**以及其一般形式**F<sub>β</sub>**

F1度量是基于查准率和查全率的**调和平均**定义的，其一般形式F<sub>β</sub>是**加权调和平均**，对查准率/查全率有不同偏好。
$$
F1定义：\frac{1}{F1}=\frac{1}{2}.(\frac{1}{P}+\frac{1}{R})\qquad (2.3-10)\\
F_{\beta}定义：\frac{1}{F_{\beta}}=\frac{1}{1+\beta^2}.(\frac{1}{P}+\frac{\beta^2}{R})\qquad (2.3-11)\\
$$
形式改写为：
$$
F1=\frac{2*P*R}{P+R}=\frac{2*TP}{\text{样例总数}+TP-TN}\qquad (2.3-12)\\
F_{\beta}=\frac{(1+\beta^2)*P*R}{(\beta^2*P)+R}\qquad (2.3-13)
$$
β>0度量查全率对查准率的相对重要性，其中：

1. β=1，即标准的F1。
2. **β>1，查全率有更大影响**，如逃犯信息检索，尽可能少漏信息。
3. **0<β<1，查准率影响更大**，如商品推荐系统，目标是推荐内容更准确且少打扰用户。

------

复杂情况

存在**多个二分类混淆矩阵**，若欲在n个混淆矩阵上考察查全率和查准率，方法如下：

- 法1：先在各混淆矩阵上分别计算出查准率和查全率，然后再计算平均值，即得到其**“宏查准率”、“宏查全率”、“相应的宏F1”**。
- 法2：先将各混淆矩阵对应元素平均，得到TP、FP、TN、FN的对应平均值，再计算出**“微查准率”、“微查全率”、“相应的微F1”**。

## 2.3.3-ROC与AUC

- 引入

学习器是为测试样本**产生1个实值或概率预测**，后将这个预测值与**1个分类阈值（或“截断点”）比较**，**预测值大于阈值则为正例**，反之为反例，**预测值好坏**直接决定**学习器泛化能力**，而根据预测值可**对测试样本排序**，排序本身的好坏体现学习器一般情况下泛化性能好坏。

ROC（受试者工作特征，receiver operating characteristic）曲线是研究学习器泛化性能的工具，

- ROC

类似于PR图，**横轴是“假正例率”（FPR）**，**纵轴是“真正例率”（TPR）**，各自定义如下：
$$
TPR=\frac{TP}{TP+FN}= \frac{TP}{正例总数}\qquad (2.3-14)\\
FPR=\frac{FP}{TN+FP}= \frac{FP}{反例总数}\qquad (2.3-15)
$$
直线**y=x对角线**对应于**“随机猜测”模型**，而**点(0,1)**对应于**所有正例排在所有反例之前**的"**理想模型**"。



基于有限个测试样例绘制ROC图，过程如下：

给定m<sup>+</sup>个正例和m<sup>-</sup>个反例，据学习器预测结果对样例排序，然后将分类阈值设为最大，即将所有样例均预测为反例，此时TPR=0、FPR=0,在（0，0）点标记1个点。

之后将分类阈值依次设计为每个样例的预测值，则对应标记点坐标是（x，y），
$$
当前为真正例，对应标记点(x,y+\frac{1}{m^+} );当前为假正例，对应标记点(x+\frac{1}{m^-},y)。
$$
之后用线段连接相邻点即得。



- 特性

1、类似PR图，学习器A的ROC曲线将学习器B的ROC曲线完全包住，则**A的性能更优**。

2、ROC曲线交叉，比较ROC曲线下面积，即AUC（area under ROC curve），即定积分。

- AUC

其考虑样本预测的排序质量，与排序误差有紧密联系。

形式化地看， AUC考虑的是样本预测的排序质量，因此它与排序误差有紧 密联系.给定m<sup>+</sup>个正例和m<sup>-</sup>个反例，令D<sup>+</sup>和D<sup>-</sup>
分别表示正、反例集合， 则排序"损失" (loss)定义为：

![image-20220824195106765](E:\affairs\my_affairs\extended_learning\notes\pics\image-20220824195106765.png)(2.3-16)

l<sub>rank</sub>即为ROC曲线上的面积.

存在
$$
AUC=1-l_{rank}\qquad (2.3-17)
$$

## 2.3.4-代价敏感错误率与代价曲线

为权衡**不同类型错误**所造成的**不同损失**，可为错误赋予“**非均等代价**”。

- 二分类代价矩阵

|              | 预测结果          |                   |
| ------------ | ----------------- | ----------------- |
| **真实情况** | 第0类             | 第1类             |
| 第0类        | 0                 | cost<sub>01</sub> |
| 第1类        | cost<sub>10</sub> | 0                 |

1. cost<sub>ij</sub>即第i类预测为第j类样本的代价。
2. 一般cost<sub>ij</sub>=0。
3. 若第0类判别为第1类的损失更大，则  cost<sub>01</sub>>  cost<sub>10</sub>。
4. 损失承担相差越大，则 cost<sub>01</sub>>与  cost<sub>10</sub>差别越大。
5. 重要的是**代价比值**，而非绝对值。

- 非均等代价

上方中的性能度量中如错误率之类基本都是基于**均等代价**的角度考虑，直接计算错误次数，而未考虑不同错误的损失。

在非均等代价下，希望的不是最小化错误次数，而是**最小化“总体代价”**。

由此引入“**代价敏感”错误率**以及**代价曲线**。