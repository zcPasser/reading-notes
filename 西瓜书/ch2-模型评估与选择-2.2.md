[TOC]

#  2.2-评估方法

使用**测试集**，测试学习器**对新样本的判别能力**。后以**测试集上的“测试误差**”作为**泛化误差的近似**。

注意：测试集应该尽可能**与训练集互斥**。

为得到泛化性能强的模型，且当只有**1个包含m个样例的数据集D**（如下图2.2-1），既要训练也要测试，需要通过对D进行适当处理，从中产生**训练集S和测试集T**。
$$
D=\{(x_1,y_1),...,(x_m,y_m)\}\qquad2.2-1
$$
方法如下：

## 2.2.1-留出法

直接将**数据集D划分为2个互斥的集合**，一个作为**训练集S**，一个作为**测试集T**。

------

注意：

- 训练集和测试集的**划分**要尽可能**保持数据分布的一致性**。

  对于分类任务，至少保持样本的类别比例相似，若从**采样**的角度来看，则**保留类别比例**的采样方式称为**分层采样**。

- 即使在给定训练集、测试集的样本比例后，仍存在多种划分方式对初始数据集D进行分割。

结论：

- **单次使用留出法**得到的估计结果**一般不可靠**，在使用留出法时，一般采用**若干次随即划分**、**重复进行试验评估**后**取平均值**作为留出法的评估结果。

问题&解法：

- 由于留出法需要将D划分为S和T，会导致**训练集S包含绝大多数样本**，则训练出的模型可能**更接近用D训练出的模型**，而**T则会较小**，**评估结果可能不准确**；若**T样本多**一些，则**训练集S与D的差别更大**了，训练出的模型和用D训练出的**模型**相比可能会有**较大差别**，从而会**降低评估结果保真性**。
  - 偏差-方差：测试集T小时，评估结果的方差较大；训练集S小时，评估结果的偏差较大。
    - 粗浅解释：以靶心图为例，中间核心区是正确预测。
      - **偏差**大：预测结果**偏离中心程度大**。
      - **方差**大：预测结果较**聚合**。
- 没有完美解决方案，常见做法是将大约**2/3~4/5**的样本用于**训练**，其余用于测试。

## 2.2.2-交叉验证法

先将**数据集D**划分为**k个大小相似的互斥子集**，每个**子集Di都尽可能保持数据分布的一致性**(即从D中通过分层采样得到)，然后**每次用k-1个子集的并集**作为**训练集**，**余下的1个**子集作为**测试集**；如此可获得**k组训练/测试集**，从而可进行**k次训练和测试**，最终返回这**k个测试结果的均值**。

交叉验证法评估结果的**稳定性和保真性**很大程度上取决于**k**，故又称k折交叉验证、k倍交叉验证。

k**最常用的取值为10**，其他常用有5、20。

------

使用细节：

- 类似留出法，将数据集D划分k个，存在多种划分方式，因此同样要随机使用不同的划分重复p次，最终评估结果是这p次k折交叉验证结果的均值，如常见的“10次10折交叉验证”，其与“100次留出法”类似，都进行了100次训练/测试。
- 若数据集D中包含m个样本，若令k=m，则得到了交叉验证法的1个特例：留一法。

## 2.2.3-自助法

上述方法都会出现实际评估的模型所使用的训练集比D小，导致因训练样本规模不同而导致的估计偏差。

自助法：以**自助采样法**为基础。

给定包含m个样本的数据集D，对其进行采样产生的数据集D‘：每次随机从D中挑选1个样本，将其拷贝放入D’，然后将该样本放回D中，使得其下次采样仍可能被采样；上述过程重复执行m次，可得到包含m个样本的数据集D‘，为结果。

由于随机采样存在概率问题，样本在m次采样中不被采到的概率为：
$$
(1\quad-\quad\frac{1}{m})^m
$$
m取无穷时存在极限，则数据集D中约有**36.8%**的样本未出现在采样数据集D’中。

因此将D‘用作训练集，D\D’（\表示集合减法）用作测试集；

如此实际评估的模型与期望评估的模型都使用m个训练样本，且仍有数据总量约**1/3**的、没在训练集中出现的样本用于测试，如此的测试结果称为“**包外估计**”。

------

使用细节：

- 在**数据集较小**、**难以有效划分训练集/测试集**时有用。
- 自助法能从初始数据集中产生**多个不同的训练集**，其对**集成学习**等方法有很大好处。

缺陷：

- 自助法产生的数据集**改变了初始数据集的分布**，会引入**估计偏差**，因此**初始数据量足够**时，留出法和交叉验证法更常用。

## 2.2.4-调参与最终模型

介绍：

- 大多学习算法有参数需要设定，参数配置不同，学得模型的性能往往有明显差别。因此除对适用学习算法进行选择，还需对算法参数进行设定，即“**参数调节**”或简称“**调参**”。

意义：

- 理论上，对每种参数训练出模型，然后将对应最好模型的参数作为结果。
- 参数大多是在实数范围内取值，而且大型“深度学习”模型甚至有上百亿个参数，这会导致极大的调参工程量。

解决：

- 给定包含m个样本的数据集D，在模型评估与选择过程中由于需要留出一部分数据进行评估测试，只使用了一部分数据训练模型。因此在**模型选择完成**后，**学习算法和参数配置都已选定**，此时应该用**数据集D重新训练模型**。该模型在训练过程中使用了**所有m个**样本，这才是**最终提交**给用户的模型。
- 对每个参数选定1个范围和变化步长。

划分：

- 测试数据：学得模型在实际使用中遇到的数据。
- 验证集：模型评估与选择中用于评估测试的数据集。
- 举例：在研究对比不同**算法的泛化性能**时，用**测试集上**的判别效果来估计模型在实际使用时的泛化能力，而把**训练数据**另外划分为**训练集**和**验证集**，基于验证集上的性能进行**模型选择和调参**。