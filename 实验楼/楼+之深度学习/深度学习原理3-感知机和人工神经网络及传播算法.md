[TOC]

# æ„ŸçŸ¥æœºå’Œäººå·¥ç¥ç»ç½‘ç»œ

## æ„ŸçŸ¥æœº

> æ„ŸçŸ¥æœºï¼ˆè‹±è¯­ï¼šPerceptronï¼‰æ˜¯ Frank Rosenblatt åœ¨ 1957 å¹´å°±èŒäº Cornell èˆªç©ºå®éªŒå®¤æ—¶æ‰€å‘æ˜çš„ä¸€ç§äººå·¥ç¥ç»ç½‘ç»œã€‚å®ƒå¯ä»¥è¢«è§†ä¸ºä¸€ç§æœ€ç®€å•å½¢å¼çš„å‰é¦ˆç¥ç»ç½‘ç»œï¼Œæ˜¯ä¸€ç§äºŒå…ƒçº¿æ€§åˆ†ç±»å™¨ã€‚

### æ„ŸçŸ¥æœºçš„æ¨å¯¼

- äºŒç»´å¹³é¢ä¸­çº¿æ€§å¯åˆ†

$$
f(x) = w_1x_1+w_2x_2+ \cdots +w_nx_n + b = WX+b \tag{1}
$$

å…¬å¼ï¼ˆ1ï¼‰ï¼Œå¯ä»¥è®¤ä¸ºæ–¹ç¨‹æ˜¯å¯¹æ•°æ®é›†æ¯ä¸€ä¸ªç‰¹å¾x1,x2,...,xnä¾æ¬¡ä¹˜ä¸Šæƒé‡w1,w2,...,wnã€‚

- äºŒåˆ†ç±»åˆ«

æœ€ç»ˆç±»åˆ«æœ‰2ä¸ªï¼Œé€šå¸¸ç§°ä¸ºæ­£ç±»åˆ«å’Œè´Ÿç±»åˆ«ã€‚å½“ä½¿ç”¨çº¿æ€§å›å½’ä¸­å¯¹åº”çš„å…¬å¼ï¼ˆ1ï¼‰å®Œæˆåˆ†ç±»æ—¶ï¼Œä¸åŒäºé€»è¾‘å›å½’ä¸­å°†f(x)ä¼ å…¥simoidå‡½æ•°ï¼Œç°åœ¨ä¼ å…¥signå‡½æ•°ï¼š
$$
\operatorname{sign}(x)=\left\{\begin{array}{ll}{+1,} & {\text { if } x \geq 0} \\ {-1,} & {\text { if }  x<0}\end{array}\right. \tag{2}
$$
å³sign(f(x))ï¼Œå½“sign=1ï¼Œä¸ºæ­£åˆ†ç±»ç‚¹ï¼Œå¦åˆ™=-1ï¼Œä¸ºè´Ÿåˆ†ç±»ç‚¹ã€‚

è®¾è¾“å…¥ç©ºé—´ï¼ˆç‰¹å¾å‘é‡ï¼‰XâŠ†ğ‘…^ğ‘›ï¼Œè¾“å‡ºç©ºé—´Y=-1ï¼Œ+1ã€‚
$$
f(x) = sign(W*x +b) \tag{3}
$$
å…¬å¼ï¼ˆ3ï¼‰ç§°ä¹‹ä¸º**æ„ŸçŸ¥æœº**ã€‚

### æ„ŸçŸ¥æœºè®¡ç®—æµç¨‹å›¾

![](D:\äº‹åŠ¡\æˆ‘çš„äº‹åŠ¡\æ‹“å±•å­¦ä¹ \ç¬”è®°\pictures\æ¥¼+æ·±åº¦å­¦ä¹ \æ„ŸçŸ¥æœºè®¡ç®—æµç¨‹å›¾.png)

### æ„ŸçŸ¥æœºæŸå¤±å‡½æ•°

> åœ¨æ„ŸçŸ¥æœºä¸­ï¼Œä¼šä½¿ç”¨è¯¯åˆ†ç±»ç‚¹åˆ°åˆ†å‰²çº¿ï¼ˆé¢ï¼‰çš„è·ç¦»å»å®šä¹‰æŸå¤±å‡½æ•°ã€‚

- ç‚¹åˆ°ç›´çº¿è·ç¦»

nç»´å®æ•°å‘é‡ç©ºé—´ä¸­ä»»æ„ä¸€ç‚¹x0åˆ°ç›´çº¿ **W * x + b = 0**çš„ è·ç¦» ä¸ºï¼š
$$
d= \dfrac{1}{\parallel W\parallel}|W*x_{0}+b| \tag{4}
$$
å…¶ä¸­ ||ğ‘Š||è¡¨ç¤º ğ¿2èŒƒæ•°ï¼Œå³å‘é‡å„å…ƒç´ çš„å¹³æ–¹å’Œç„¶åå¼€æ–¹ã€‚
$$
å¯¹äºç‚¹ (x_i,y_i)ï¼Œä½¿ç”¨å…¬å¼ (3) è¿›è¡Œåˆ†ç±»æ—¶ï¼Œå¦‚æœ W*x_i+b>0ï¼Œåˆ™ sign(W*x_i+b)=1ã€‚\\
é‚£ä¹ˆï¼Œæ­¤ç‚¹çš„é¢„æµ‹åˆ†ç±»ä¸º +1ï¼Œåä¹‹é¢„æµ‹åˆ†ç±»ä¸º -1ã€‚\\
å¦‚æœæ­¤ç‚¹çš„çœŸå®åˆ†ç±»ä¸é¢„æµ‹åˆ†ç±»ä¸åŒï¼Œåˆ™ç§°ä¸ºè¯¯åˆ†ç±»ç‚¹ã€‚\\
å¯¹äºè¯¯åˆ†ç±»ç‚¹ï¼ŒçœŸå®çš„ y_i = +1ï¼Œä½†ä½¿ç”¨æ„ŸçŸ¥æœºç®—å‡ºæ¥çš„ W * x_i + b < 0ï¼›\\
æˆ–è€…çœŸå®çš„ y_i = -1ï¼Œä½†ä½¿ç”¨æ„ŸçŸ¥æœºç®—å‡ºæ¥çš„ W * x_i + b > 0ã€‚\\
è¿™ä¸¤ç§æƒ…å†µä¸‹ y_i(W * x_{i}+ b) < 0 å‡æˆç«‹ï¼Œå³å¯¹äºè¯¯åˆ†ç±»ç‚¹ï¼Œå…¬å¼ (5) æˆç«‹ã€‚
$$
ç‚¹é¢è· æˆ– è¯¯åˆ†ç±»ç‚¹åˆ°åˆ†å‰²çº¿ï¼š
$$
d=-\dfrac{1}{\parallel W\parallel}y_i(W*x_{i}+b) \tag{6}
$$
æ„ŸçŸ¥æœºæŸå¤±å‡½æ•°ï¼š
$$
J(W,b) = - \sum_{x_i\epsilon M} y_i(W*x_{i}+b) \tag{8}
$$
ä»å…¬å¼ (8) å¯ä»¥çœ‹å‡ºï¼Œ**æŸå¤±å‡½æ•° ğ½(ğ‘Š,ğ‘) æ˜¯éè´Ÿ**çš„ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå½“æ²¡æœ‰è¯¯åˆ†ç±»ç‚¹æ—¶ï¼ŒæŸå¤±å‡½æ•°çš„å€¼ä¸º **0**ã€‚åŒæ—¶ï¼Œ**è¯¯åˆ†ç±»ç‚¹è¶Šå°‘**ï¼Œè¯¯åˆ†ç±»ç‚¹è·ç¦»åˆ†å‰²çº¿ï¼ˆé¢ï¼‰å°±**è¶Šè¿‘**ï¼ŒæŸå¤±å‡½æ•°å€¼å°±**è¶Šå°**ã€‚åŒæ—¶ï¼ŒæŸå¤±å‡½æ•° ğ½(ğ‘Š,ğ‘)J(W,b) æ˜¯**è¿ç»­å¯å¯¼å‡½æ•°**ã€‚

### éšæœºæ¢¯åº¦ä¸‹é™æ³•

> ç±»ä¼¼äºé€»è¾‘å›å½’ä¸­ï¼Œä¸ºäº†æ‰¾åˆ°æŸå¤±å‡½æ•°çš„æå°å€¼ï¼Œä¹Ÿé‡‡ç”¨äº†ä¸€ç§æ¢¯åº¦ä¸‹é™æ³•çš„æ”¹è¿›æ–¹æ³•ï¼Œä¹Ÿç§°ä¸ºéšæœºæ¢¯åº¦ä¸‹é™æ³•SGDã€‚

- SGDéšæœºæ¢¯åº¦ä¸‹é™ç®—æ³•å®ç°

```python
from sklearn.utils import shuffle


def perceptron_sgd(X, Y, alpha, epochs):
    """
    å‚æ•°:
    X -- è‡ªå˜é‡æ•°æ®çŸ©é˜µ
    Y -- å› å˜é‡æ•°æ®çŸ©é˜µ
    alpha -- lamda å‚æ•°
    epochs -- è¿­ä»£æ¬¡æ•°

    è¿”å›:
    w -- æƒé‡ç³»æ•°
    b -- æˆªè·é¡¹
    """
    # æ„ŸçŸ¥æœºéšæœºæ¢¯åº¦ä¸‹é™ç®—æ³•å®ç°
    w = np.zeros(len(X[0]))  # åˆå§‹åŒ–å‚æ•°ä¸º 0
    b = np.zeros(1)

    for t in range(epochs):  # è¿­ä»£
        # æ¯ä¸€æ¬¡è¿­ä»£å¾ªç¯æ‰“ä¹±è®­ç»ƒæ ·æœ¬
        # X, Y = shuffle(X, Y)
        for i, x in enumerate(X):
            if ((np.dot(X[i], w)+b)*Y[i]) <= 0:  # åˆ¤æ–­æ¡ä»¶
                w = w + alpha*X[i]*Y[i]  # æ›´æ–°å‚æ•°
                b = b + alpha*Y[i]

    return w, b
```

### æ„ŸçŸ¥æœºåˆ†ç±»å®ä¾‹

```python
# æ•°æ®é›†
import pandas as pd

df = pd.read_csv(
    "https://labfile.oss.aliyuncs.com/courses/1081/course-12-data.csv", header=0)  # åŠ è½½æ•°æ®é›†
df.head()  # é¢„è§ˆå‰ 5 è¡Œæ•°æ®

'''
è¯¥æ•°æ®é›†å…±æœ‰ä¸¤ä¸ªç‰¹å¾å˜é‡ X0 å’Œ X1, ä»¥åŠä¸€ä¸ªç›®æ ‡å€¼ Yã€‚å…¶ä¸­ï¼Œç›®æ ‡å€¼ Y åªåŒ…å« -1 å’Œ 1ã€‚
'''

# ä½¿ç”¨æ„ŸçŸ¥æœºæ±‚è§£æœ€ä½³åˆ†å‰²çº¿ã€‚
import numpy as np

X = df[['X0', 'X1']].values
Y = df['Y'].values

alpha = 0.1
epochs = 150

perceptron_sgd(X, Y, alpha, epochs)
```

æ±‚å¾—çš„æœ€ä½³åˆ†å‰²çº¿æ–¹ç¨‹ï¼š
$$
f(x)=4.93 * x_{1}-6.98 * x_{2}-3.3 \tag{12}
$$


```python
def perceptron_loss(X, Y, alpha, epochs):
    """
    å‚æ•°:
    X -- è‡ªå˜é‡æ•°æ®çŸ©é˜µ
    Y -- å› å˜é‡æ•°æ®çŸ©é˜µ
    alpha -- lamda å‚æ•°
    epochs -- è¿­ä»£æ¬¡æ•°

    è¿”å›:
    loss_list -- æ¯æ¬¡è¿­ä»£æŸå¤±å‡½æ•°å€¼åˆ—è¡¨
    """
    # è®¡ç®—æ¯æ¬¡è¿­ä»£åçš„æŸå¤±å‡½æ•°å€¼
    w = np.zeros(len(X[0]))  # åˆå§‹åŒ–å‚æ•°ä¸º 0
    b = np.zeros(1)
    loss_list = []

    for t in range(epochs):  # è¿­ä»£
        loss_init = 0
        for i, x in enumerate(X):
            # æ¯ä¸€æ¬¡è¿­ä»£å¾ªç¯æ‰“ä¹±è®­ç»ƒæ ·æœ¬
            # X, Y = shuffle(X, Y)
            if ((np.dot(X[i], w)+b)*Y[i]) <= 0:  # åˆ¤æ–­æ¡ä»¶
                loss_init += (((np.dot(X[i], w)+b)*Y[i]))
                w = w + alpha*X[i]*Y[i]  # æ›´æ–°å‚æ•°
                b = b + alpha*Y[i]
        loss_list.append(loss_init * -1)

    return loss_list
```

å½“æ•°æ®é›†çº¿æ€§å¯åˆ†ï¼Œå´é€ æˆæŸå¤±å‡½æ•°å˜æ¢æ›²çº¿éœ‡è¡çš„åŸå› ï¼š

1. **å­¦ä¹ ç‡å¤ªå¤§**ã€‚
2. **è¿­ä»£æ¬¡æ•°å¤ªå°‘**ã€‚

```python
alpha = 0.05  # å‡å°å­¦ä¹ ç‡
epochs = 1000  # å¢åŠ è¿­ä»£æ¬¡æ•°
```

## äººå·¥ç¥ç»ç½‘ç»œ

> æ„ŸçŸ¥æœºåªèƒ½å¤„ç†äºŒåˆ†ç±»é—®é¢˜ï¼Œä¸”å¿…é¡»æ˜¯çº¿æ€§å¯åˆ†é—®é¢˜ã€‚
>
> äººå·¥ç¥ç»ç½‘ç»œï¼Œå³ Artificial Neural Networkï¼ˆANNï¼‰

### å¤šå±‚æ„ŸçŸ¥æœºä¸äººå·¥ç¥ç»ç½‘ç»œ

- äººå·¥ç¥ç»ç½‘ç»œ

æ„ŸçŸ¥æœºä¹Ÿæ˜¯1ä¸ªäººå·¥ç¥ç»ç½‘ç»œï¼Œæ˜¯ç®€å•çš„**å•å±‚ç¥ç»ç½‘ç»œ**ã€‚

äººå·¥ç¥ç»ç½‘ç»œå¯ä»¥ç”¨æ¥è§£å†³ **çº¿æ€§ä¸å¯åˆ†** æˆ–è€… **å¤šåˆ†ç±»é—®é¢˜**ï¼Œ å°†**å¤šä¸ªæ„ŸçŸ¥æœºç»„åˆ**ã€‚

äººå·¥ç¥ç»ç½‘ç»œæŸç§æ„ä¹‰ä¸Š ä»£æŒ‡ **å¤šå±‚æ„ŸçŸ¥æœº**ã€‚

- å•å±‚æ„ŸçŸ¥æœºçš„ç²¾ç®€æµç¨‹å›¾

![](D:\äº‹åŠ¡\æˆ‘çš„äº‹åŠ¡\æ‹“å±•å­¦ä¹ \ç¬”è®°\pictures\æ¥¼+æ·±åº¦å­¦ä¹ \æ„ŸçŸ¥æœºè®¡ç®—æµç¨‹å›¾-ç²¾ç®€.png)

å¦‚ä¸ŠåªåŒ…å«1ä¸ªè¾“å…¥å±‚çš„ç½‘ç»œç»“æ„ å¯ä»¥ ç§°ä¹‹ä¸º å•å±‚ç¥ç»ç½‘ç»œç»“æ„ã€‚

- å¤šå±‚æ„ŸçŸ¥æœº

> å°†1ä¸ªæ„ŸçŸ¥æœºçš„è¾“å‡ºä½œä¸ºå¦ä¸€ä¸ªæ„ŸçŸ¥æœºçš„è¾“å…¥ã€‚

è¾“å…¥å±‚å’Œè¾“å‡ºå±‚ä¹‹é—´çš„ç§°ä¸º**éšå«å±‚**ã€‚

ä¸€ä¸ªç¥ç»ç½‘ç»œç»“æ„è®¡ç®—å±‚æ•°æ—¶ï¼Œä¸€èˆ¬**åªè®¡ç®—è¾“å…¥å’Œéšå«å±‚çš„æ•°é‡**

![](D:\äº‹åŠ¡\æˆ‘çš„äº‹åŠ¡\æ‹“å±•å­¦ä¹ \ç¬”è®°\pictures\æ¥¼+æ·±åº¦å­¦ä¹ \ç¥ç»ç½‘ç»œç»“æ„å›¾-1ä¸ªéšå«å±‚.png)

ä¸Šå›¾ä¸­ä¸º1ä¸ª**2å±‚ç¥ç»ç½‘ç»œç»“æ„**ã€‚

### æ¿€æ´»å‡½æ•°

$$
f(x) = w_1x_1+w_2x_2+ \cdots +w_nx_n + b = WX+b \tag{13}
$$

- é€»è¾‘å›å½’

é‡‡ç”¨sigmoidå‡½æ•°ï¼Œå°†f(x)è½¬ä¸º æ¦‚ç‡ï¼Œ æœ€ç»ˆå®ç° äºŒåˆ†ç±»ã€‚

- æ„ŸçŸ¥æœº

é‡‡ç”¨signå‡½æ•°ï¼Œ å°†f(x)è½¬ä¸º-1 å’Œ 1 ï¼Œæœ€ç»ˆå®ç°äºŒåˆ†ç±»ã€‚

- å¤šå±‚æ„ŸçŸ¥æœº

å…·æœ‰å¤šå±‚æ„ŸçŸ¥æœºã€‚

> ä¸Šè¿°ä¸­sigmoidã€signä¹Ÿç§° æ¿€æ´»å‡½æ•°ã€‚

#### æ¿€æ´»å‡½æ•°ä½œç”¨

- ç®€è€Œè¨€ä¹‹

é’ˆå¯¹æ•°æ®è¿›è¡Œ**éçº¿æ€§å˜æ¢**ã€‚

å› ä¸º**çº¿æ€§å˜æ¢çš„å¤šé‡ç»„åˆä¾æ—§æ˜¯çº¿æ€§å˜æ¢**ï¼Œæ²¡æœ‰æ„ä¹‰ï¼Œè€ŒåŠ å…¥æ¿€æ´»å‡½æ•°ï¼Œå³å¼•å…¥äº†**éçº¿æ€§å› **ç´ ï¼Œå¯ä»¥è§£å†³çº¿æ€§æ¨¡å‹æ— æ³•å®Œæˆçš„åˆ†ç±»ä»»åŠ¡ã€‚

### åå‘ä¼ æ’­ç®—æ³•BP

> ä¹‹å‰æ„ŸçŸ¥æœºä¸­ï¼Œå®šä¹‰äº†æŸå¤±å‡½æ•°ï¼Œé€šè¿‡éšæœºæ¢¯åº¦ä¸‹é™æ–¹æ³•æ±‚è§£æœ€ä¼˜å‚æ•°ã€‚
>
> è€Œæ„ŸçŸ¥æœºåªæœ‰ä¸€å±‚ï¼Œæ±‚è§£æ¢¯åº¦è¾ƒç®€å•ï¼Œåœ¨å¤šå±‚ç»“æ„ä¸­ï¼Œæ›´æ–°æƒé‡è¿‡ç¨‹å˜å¾—å¤æ‚ï¼Œè€Œåå‘ä¼ æ’­ç®—æ³•BPå¯å¸®åŠ©å¿«é€Ÿæ±‚è§£æ¢¯åº¦ã€‚

- 3å±‚ç¥ç»ç½‘ç»œç»“æ„

![](D:\äº‹åŠ¡\æˆ‘çš„äº‹åŠ¡\æ‹“å±•å­¦ä¹ \ç¬”è®°\pictures\æ¥¼+æ·±åº¦å­¦ä¹ \å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­\3å±‚ç¥ç»ç½‘ç»œç»“æ„å›¾.png)

1. æœ‰2ä¸ªè¾“å…¥x1 ã€ x2  å’Œ 1ä¸ªè¾“å‡º yã€‚

2. æ¯ä¸ªç´«è‰²å•å…ƒè¡¨ç¤º1ä¸ªç‹¬ç«‹ç¥ç»å…ƒï¼Œåˆ†åˆ«ç”±2ä¸ªå•å…ƒç»„æˆï¼Œ1ä¸ªå•å…ƒæ˜¯æƒé‡å’Œè¾“å…¥ä¿¡å·ï¼Œ1ä¸ªæ˜¯æ¿€æ´»å‡½æ•°ï¼Œå…¶ä¸­ï¼Œeè¡¨ç¤ºæ¿€æ´»ä¿¡å·ï¼Œæ‰€ä»¥ y=f(e)è¡¨ç¤ºè¢«æ¿€æ´»å‡½æ•°å¤„ç†ä¹‹åçš„éçº¿æ€§è¾“å‡ºï¼Œå³ç¥ç»å…ƒçš„è¾“å‡ºã€‚

   ![](D:\äº‹åŠ¡\æˆ‘çš„äº‹åŠ¡\æ‹“å±•å­¦ä¹ \ç¬”è®°\pictures\æ¥¼+æ·±åº¦å­¦ä¹ \å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­\ç¥ç»å…ƒå¤„ç†æµå›¾.png)

3. 

#### å‰å‘ä¼ æ’­è¿‡ç¨‹

> å¼€å§‹è®­ç»ƒç¥ç»ç½‘ç»œï¼Œè®­ç»ƒæ•°æ®ç”±è¾“å…¥ä¿¡å·x1 å’Œ x2 ä»¥åŠ æœŸæœ›è¾“å‡ºzç»„æˆã€‚

- è®¡ç®—ç¬¬1ä¸ªéšå«å±‚ä¸­ç¬¬1ä¸ªç¥ç»å…ƒy1 = f1(e)å¯¹åº”å€¼

![](D:\äº‹åŠ¡\æˆ‘çš„äº‹åŠ¡\æ‹“å±•å­¦ä¹ \ç¬”è®°\pictures\æ¥¼+æ·±åº¦å­¦ä¹ \å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­\å‰å‘ä¼ æ’­1.png)

- è®¡ç®—ç¬¬1ä¸ªéšå«å±‚ä¸­ç¬¬3ä¸ªç¥ç»å…ƒy2 = f2(e)å€¼

![](D:\äº‹åŠ¡\æˆ‘çš„äº‹åŠ¡\æ‹“å±•å­¦ä¹ \ç¬”è®°\pictures\æ¥¼+æ·±åº¦å­¦ä¹ \å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­\å‰å‘ä¼ æ’­2.png)

- ...
- ç¬¬2ä¸ªéšå«å±‚ç¬¬1ä¸ªç¥ç»å…ƒ

![](D:\äº‹åŠ¡\æˆ‘çš„äº‹åŠ¡\æ‹“å±•å­¦ä¹ \ç¬”è®°\pictures\æ¥¼+æ·±åº¦å­¦ä¹ \å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­\å‰å‘ä¼ æ’­4.png)

- ...
- å¾—åˆ°è¾“å‡ºå±‚ç»“æœ

![](D:\äº‹åŠ¡\æˆ‘çš„äº‹åŠ¡\æ‹“å±•å­¦ä¹ \ç¬”è®°\pictures\æ¥¼+æ·±åº¦å­¦ä¹ \å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­\å‰å‘ä¼ æ’­6.png)

#### åå‘ä¼ æ’­

> å¾—åˆ°å‰å‘ä¼ æ’­çš„è¾“å‡ºç»“æœyæ—¶ï¼Œ å’ŒæœŸæœ›è¾“å‡ºz å¯¹æ¯”ï¼Œ å¾—åˆ°è¯¯å·®ğ›¿ï¼Œç„¶åæ ¹æ®è¯¯å·®ğ›¿ï¼Œæ²¿ç€ç¥ç»å…ƒå›è·¯åå‘ä¼ é€’ï¼Œæ¯ä¸ªç¥ç»å…ƒå¯¹åº”è¯¯å·®å³ä¸ºä¼ é€’çš„è¯¯å·® * æƒé‡ã€‚

- è®¡ç®—ç¬¬2å±‚éšå«å±‚ç¬¬1ä¸ªç¥ç»å…ƒçš„è¯¯å·®è®¡ç®—

![](D:\äº‹åŠ¡\æˆ‘çš„äº‹åŠ¡\æ‹“å±•å­¦ä¹ \ç¬”è®°\pictures\æ¥¼+æ·±åº¦å­¦ä¹ \å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­\åå‘ä¼ æ’­-è¯¯å·®1.png)

- ...
- è®¡ç®—ç¬¬1å±‚éšå«å±‚ç¬¬1ä¸ªç¥ç»å…ƒè¯¯å·®

![](D:\äº‹åŠ¡\æˆ‘çš„äº‹åŠ¡\æ‹“å±•å­¦ä¹ \ç¬”è®°\pictures\æ¥¼+æ·±åº¦å­¦ä¹ \å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­\åå‘ä¼ æ’­-è¯¯å·®3.png)

- ...

> åˆ©ç”¨åå‘ä¼ é€’çš„è¯¯å·®ï¼Œä»è¾“å…¥å±‚å¼€å§‹ï¼Œä¾æ¬¡æ›´æ–°æƒé‡wã€‚

- æ›´æ–°æƒé‡w11

![](D:\äº‹åŠ¡\æˆ‘çš„äº‹åŠ¡\æ‹“å±•å­¦ä¹ \ç¬”è®°\pictures\æ¥¼+æ·±åº¦å­¦ä¹ \å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­\åå‘ä¼ æ’­-æƒé‡æ›´æ–°1.png)

- ...
- æ›´æ–°æƒé‡w46 å’Œ w56

![](D:\äº‹åŠ¡\æˆ‘çš„äº‹åŠ¡\æ‹“å±•å­¦ä¹ \ç¬”è®°\pictures\æ¥¼+æ·±åº¦å­¦ä¹ \å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­\åå‘ä¼ æ’­-æƒé‡æ›´æ–°6.png)

>  ğœ‚ è¡¨ç¤º å­¦ä¹ é€Ÿç‡

ä»¥ä¸Šï¼šå‰å‘ä¼ æ’­è®¡ç®—ç¥ç»å…ƒå€¼ - è·å–è¯¯å·® - åå‘é€å±‚è®¡ç®—è¯¯å·® - å‰å‘æ›´æ–°æƒé‡ã€‚ä¸º1ä¸ªè¿­ä»£è¿‡ç¨‹ã€‚



### pythonå®ç°äººå·¥ç¥ç»ç½‘ç»œ

> ä½¿ç”¨ç®€æ˜“çš„2å±‚äººå·¥ç¥ç»ç½‘ç»œç»“æ„ï¼Œ1å±‚éšå«å±‚ï¼ˆ3ä¸ªç¥ç»å…ƒï¼‰ï¼Œ1å±‚è¾“å…¥å±‚ï¼ˆ2ä¸ªç¥ç»å…ƒï¼‰ï¼Œé€šè¿‡è¾“å‡ºå±‚å®ç°2åˆ†ç±»é—®é¢˜æ±‚è§£

- äººå·¥ç¥ç»ç½‘ç»œç»“æ„å›¾

![pythonå®ç°çš„äººå·¥ç¥ç»ç½‘ç»œ](D:\äº‹åŠ¡\æˆ‘çš„äº‹åŠ¡\æ‹“å±•å­¦ä¹ \ç¬”è®°\pictures\æ¥¼+æ·±åº¦å­¦ä¹ \å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­\pythonå®ç°çš„äººå·¥ç¥ç»ç½‘ç»œ.png)

- æ¿€æ´»å‡½æ•°sigmoidå‡½æ•°

$$
\mathit{sigmoid}(x) = \frac{1}{1+e^{-x}}       \tag{17a}
$$

å…¶å¯¼æ•°å…¬å¼ï¼š
$$
\Delta \mathit{sigmoid}(x)  = \mathit{sigmoid}(x)(1 - \mathit{sigmoid}(x))    \tag{17b}
$$
pythonå®ç°

```python
def sigmoid(x):
    # sigmoid å‡½æ•°
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    # sigmoid å‡½æ•°æ±‚å¯¼
    return sigmoid(x) * (1 - sigmoid(x))
```

- å‰å‘ä¼ æ’­

å‰å‘ä¼ æ’­ä¸­ï¼Œæ¯ä¸€ä¸ªç¥ç»å…ƒè®¡ç®—æµç¨‹ï¼š**çº¿æ€§å˜æ¢ - æ¿€æ´»å‡½æ•° - è¾“å‡ºå€¼**ã€‚

> - ğ‘ è¡¨ç¤ºéšå«å±‚è¾“å‡ºï¼Œğ‘Œ åˆ™ä¸ºè¾“å‡ºå±‚æœ€ç»ˆè¾“å‡ºã€‚
> - ğ‘¤ğ‘–ğ‘— è¡¨ç¤ºä»ç¬¬ ğ‘– å±‚çš„ç¬¬ ğ‘— ä¸ªæƒé‡ã€‚

æ‰€ä»¥æœ‰è¾“å…¥Xï¼Œç¬¬ä¸€å±‚æƒé‡ W1 ï¼Œç¬¬äºŒå±‚æƒé‡ W2 ï¼Œ4.
$$
X=\left[ \begin{array}{ll}{x_{1}} & {x_{2}}\end{array}\right] \tag{18}
$$

$$
W_{1}=\left[ \begin{array}{lll}{w_{11}} & {w_{12}} & {w_{13}} \\ {w_{14}} & {w_{15}} & {w_{16}}\end{array}\right] \tag{19}
$$

$$
W_{2}=\left[ \begin{array}{c}{w_{21}} \\ {w_{22}} \\ {w_{23}}\end{array}\right] \tag{20}
$$

ä¸ºæ–¹ä¾¿è®¡ç®—æ¸…æ™°ï¼Œå‡è®¾æ­¤å¤„æˆªè·é¡¹ = 0ï¼Œåˆ™éšå«å±‚ç¥ç»å…ƒè¾“å‡ºZ ã€‚
$$
Z = \mathit{sigmoid}(X \cdot W_{1}) \tag{21}
$$
è¾“å‡ºå±‚Yï¼š
$$
Y = \mathit{sigmoid}(Z \cdot W_{2}) \tag{22}
$$
python

```python
# ç¤ºä¾‹æ ·æœ¬
X = np.array([[1, 1]])
y = np.array([[1]])

# ç„¶åï¼Œéšæœºåˆå§‹åŒ–éšå«å±‚æƒé‡ã€‚
W1 = np.random.rand(2, 3) # 2è¡Œ3åˆ— çš„éšæœºæ•°ç»„
W2 = np.random.rand(3, 1)

# å‰å‘ä¼ æ’­çš„è¿‡ç¨‹å®ç°åŸºäºå…¬å¼  (21)  å’Œå…¬å¼  (22)  å®Œæˆ
input_layer = X  # è¾“å…¥å±‚
hidden_layer = sigmoid(np.dot(input_layer, W1))  # éšå«å±‚ï¼Œå…¬å¼ 20
output_layer = sigmoid(np.dot(hidden_layer, W2))  # è¾“å‡ºå±‚ï¼Œå…¬å¼ 22
```



- åå‘ä¼ æ’­

> - ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³• ä¼˜åŒ–ç¥ç»ç½‘ç»œçš„ å‚æ•°ã€‚
>
> - å®šä¹‰æŸå¤±å‡½æ•°
> - è®¡ç®—æŸå¤±å‡½æ•°å…³äºç¥ç»ç½‘ç»œä¸­å„å±‚çš„æƒé‡çš„åå¯¼æ•°ï¼ˆæ¢¯åº¦ï¼‰ã€‚

è®¾ç¥ç»ç½‘ç»œçš„è¾“å‡ºå€¼Y ï¼Œ çœŸå®å€¼ yã€‚

å®šä¹‰å¹³æ–¹æŸå¤±å‡½æ•°ï¼š
$$
Loss(y, Y) = \sum (y - Y)^2 \tag{23}
$$
æ±‚è§£æ¢¯åº¦ï¼ˆé“¾å¼æ±‚å¯¼æ³•åˆ™ï¼‰ï¼š
$$
\frac{\partial Loss(y, Y)}{\partial{W_2}} = \frac{\partial Loss(y, Y)}{\partial{Y}} \frac{\partial Y}{\partial{W_2}}\tag{24a}
$$

$$
\frac{\partial Loss(y, Y)}{\partial{W_2}} = 2(Y-y) * \Delta \mathit{sigmoid}(Z \cdot W_2) \cdot Z\tag{24b}
$$

åŒç†å¯¹W1 æ±‚æ¢¯åº¦
$$
\frac{\partial Loss(y, Y)}{\partial{W_1}} = \frac{\partial Loss(y, Y)}{\partial{Y}} \frac{\partial Y }{\partial{Z}} \frac{\partial Z}{\partial{W_1}} \tag{25a}
$$

$$
\frac{\partial Loss(y, Y)}{\partial{W_1}} = 2(Y-y) * \Delta \mathit{sigmoid}(Z \cdot W_2) \cdot W_2 * \Delta \mathit{sigmoid}(X \cdot W_1) \cdot X \tag{25b}
$$

python

```python
# å…¬å¼ 24
d_W2 = np.dot(hidden_layer.T, (2 * (output_layer - y) *
                               sigmoid_derivative(np.dot(hidden_layer, W2))))

# å…¬å¼ 25
d_W1 = np.dot(input_layer.T, (
    np.dot(2 * (output_layer - y) * sigmoid_derivative(
           np.dot(hidden_layer, W2)), W2.T) * sigmoid_derivative(np.dot(input_layer, W1))))

# è®¾ç½®å­¦ä¹ ç‡ï¼Œå¯¹W1 W2è¿›è¡Œä¸€æ¬¡æ›´æ–°
# æ¢¯åº¦ä¸‹é™æ›´æ–°æƒé‡, å­¦ä¹ ç‡ä¸º 0.05
W1 -= 0.05 * d_W1  # å¦‚æœä¸Šé¢æ˜¯ y - output_layerï¼Œåˆ™æ”¹æˆ +=
W2 -= 0.05 * d_W2
```

> ä»¥ä¸Šï¼Œæˆ‘ä»¬å°±å®ç°äº†å•ä¸ªæ ·æœ¬åœ¨ç¥ç»ç½‘ç»œä¸­çš„ 1 æ¬¡å‰å‘ â†’ åå‘ä¼ é€’ï¼Œå¹¶ä½¿ç”¨æ¢¯åº¦ä¸‹é™å®Œæˆ 1 æ¬¡æƒé‡æ›´æ–°ã€‚

å®Œæ•´ç¥ç»ç½‘ç»œ

```python
# ç¤ºä¾‹ç¥ç»ç½‘ç»œå®Œæ•´å®ç°
class NeuralNetwork:

    # åˆå§‹åŒ–å‚æ•°
    def __init__(self, X, y, lr):
        self.input_layer = X
        self.W1 = np.random.rand(self.input_layer.shape[1], 3)
        self.W2 = np.random.rand(3, 1)
        self.y = y
        self.lr = lr
        self.output_layer = np.zeros(self.y.shape)

    # å‰å‘ä¼ æ’­
    def forward(self):
        self.hidden_layer = sigmoid(np.dot(self.input_layer, self.W1))
        self.output_layer = sigmoid(np.dot(self.hidden_layer, self.W2))

    # åå‘ä¼ æ’­
    def backward(self):
        d_W2 = np.dot(self.hidden_layer.T, (2 * (self.output_layer - self.y) *                       sigmoid_derivative(np.dot(self.hidden_layer, self.W2))))

        d_W1 = np.dot(self.input_layer.T, (
            np.dot(2 * (self.output_layer - self.y) * sigmoid_derivative(
                   np.dot(self.hidden_layer, self.W2)), self.W2.T) * sigmoid_derivative(np.dot(self.input_layer, self.W1))))

        # å‚æ•°æ›´æ–°
        self.W1 -= self.lr * d_W1
        self.W2 -= self.lr * d_W2
        
# å¼€å§‹æµ‹è¯•
X = df[['X0', 'X1']].values  # è¾“å…¥å€¼
y = df[['Y']].values # çœŸå® y

# å°†å…¶è¾“å…¥åˆ°ç½‘ç»œä¸­ï¼Œå¹¶è¿­ä»£ 100 æ¬¡
nn = NeuralNetwork(X, y, lr=0.001)  # å®šä¹‰æ¨¡å‹
loss_list = []  # å­˜æ”¾æŸå¤±æ•°å€¼å˜åŒ–

for i in range(100):
    nn.forward()  # å‰å‘ä¼ æ’­
    nn.backward()  # åå‘ä¼ æ’­
    loss = np.sum((y - nn.output_layer)**2)  # è®¡ç®—å¹³æ–¹æŸå¤±
    loss_list.append(loss)

print("final loss:", loss)
plt.plot(loss_list)  # ç»˜åˆ¶ loss æ›²çº¿å˜åŒ–å›¾
```

ç”±äºæƒé‡æ˜¯**éšæœºåˆå§‹åŒ–**ï¼Œå¤šæ¬¡è¿è¡Œçš„**ç»“æœä¼šä¸åŒ**ã€‚